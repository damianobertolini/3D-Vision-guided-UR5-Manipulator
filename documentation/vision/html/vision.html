<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Robotics project &mdash; vision 0.0.1 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Project report" href="report.html" />
    <link rel="prev" title="Welcome to vision’s documentation!" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            vision
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Robotics project</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-vision.visione_lab">Vision module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#vision.visione_lab.calculate_depth"><code class="docutils literal notranslate"><span class="pre">calculate_depth()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#vision.visione_lab.canny_img"><code class="docutils literal notranslate"><span class="pre">canny_img()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#vision.visione_lab.experimental_detect"><code class="docutils literal notranslate"><span class="pre">experimental_detect()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#vision.visione_lab.from_cropped_to_real_world_coord"><code class="docutils literal notranslate"><span class="pre">from_cropped_to_real_world_coord()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#vision.visione_lab.from_raw_to_jpg_compliant"><code class="docutils literal notranslate"><span class="pre">from_raw_to_jpg_compliant()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#vision.visione_lab.get_inclination"><code class="docutils literal notranslate"><span class="pre">get_inclination()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#vision.visione_lab.image_depth_processing"><code class="docutils literal notranslate"><span class="pre">image_depth_processing()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#vision.visione_lab.listener"><code class="docutils literal notranslate"><span class="pre">listener()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#vision.visione_lab.min_area_rect"><code class="docutils literal notranslate"><span class="pre">min_area_rect()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#vision.visione_lab.pca"><code class="docutils literal notranslate"><span class="pre">pca()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#vision.visione_lab.process_image"><code class="docutils literal notranslate"><span class="pre">process_image()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#vision.visione_lab.processing_callback"><code class="docutils literal notranslate"><span class="pre">processing_callback()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#vision.visione_lab.receive_image"><code class="docutils literal notranslate"><span class="pre">receive_image()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#vision.visione_lab.receive_pointcloud"><code class="docutils literal notranslate"><span class="pre">receive_pointcloud()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Project report</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="report.html">Project report</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">vision</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Robotics project</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/vision.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="robotics-project">
<h1>Robotics project<a class="headerlink" href="#robotics-project" title="Permalink to this heading"></a></h1>
<section id="module-vision.visione_lab">
<span id="vision-module"></span><h2>Vision module<a class="headerlink" href="#module-vision.visione_lab" title="Permalink to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="vision.visione_lab.calculate_depth">
<span class="sig-prename descclassname"><span class="pre">vision.visione_lab.</span></span><span class="sig-name descname"><span class="pre">calculate_depth</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">res_mult</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/vision/visione_lab.html#calculate_depth"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#vision.visione_lab.calculate_depth" title="Permalink to this definition"></a></dt>
<dd><p>Calculates the depth value given a 2D point’s coordinates. Since some depth values could be None a workaround has been implemented which just calculates the avergage of the depths of the points
within a certain range from the given point</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Integer</em>) – Coordinates of the point</p></li>
<li><p><strong>y</strong> (<em>Integer</em>) – Coordinates of the point</p></li>
<li><p><strong>res_mult</strong> (<em>Float</em>) – Parameter necessary due to image scaling</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>2D coordinates in the original image (x,y)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="vision.visione_lab.canny_img">
<span class="sig-prename descclassname"><span class="pre">vision.visione_lab.</span></span><span class="sig-name descname"><span class="pre">canny_img</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aperture_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/vision/visione_lab.html#canny_img"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#vision.visione_lab.canny_img" title="Permalink to this definition"></a></dt>
<dd><p>Filters the image passes an input through Canny algorithm in order to perform edge detection</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>img</strong> (<em>numpy array</em>) – The image to execute the detection on</p></li>
<li><p><strong>aperture_size</strong> (<em>Integer</em>) – Parameter that represents the size of the kernel for detecting edges</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>image filtered through Canny algorithm</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="vision.visione_lab.experimental_detect">
<span class="sig-prename descclassname"><span class="pre">vision.visione_lab.</span></span><span class="sig-name descname"><span class="pre">experimental_detect</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">original_img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img_centre</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">no_blur</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">redone_canny</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/vision/visione_lab.html#experimental_detect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#vision.visione_lab.experimental_detect" title="Permalink to this definition"></a></dt>
<dd><p>Searches for circles in the image passed as input using the cv2.HoughCircles() function, then tries to guess a first inclination based on those circle’s position.
In particular, after finding the circles, it finds the best line that represents all the center of the circles (least squares polynomial fit) and uses its parameters
and the distance between the mean of the circles’ centers and the block’s center to determine whether the circles are mainly on top/bottom/right/left of the block.
Since some blocks may have just one circle on (for example) the top-right corner, it returns a list where the first element is the “predominant” direction (easier to be right)
and the second element is the other less dominant one.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>original_img</strong> (<em>numpy array</em>) – The image cropped which is supposed to contain the block</p></li>
<li><p><strong>img_centre</strong> (<em>Tuple</em>) – Center of the rectangle found in the previous functions</p></li>
<li><p><strong>name</strong> (<em>String</em>) – Class of the block</p></li>
<li><p><strong>no_blur</strong> (<em>Boolean</em>) – Parameter used for deciding whether to apply a blur to the image before recognizing circles. In case no circles are detected at first, we can try removing the blur to make the image more clear</p></li>
<li><p><strong>redone_canny</strong> (<em>Boolean</em>) – Parameter that tells whether the detection has already been performed both with blur and without it (also with other improvements in the image quality). If still no circles are found,
then image has a too bad quality or no circles are present. This could mean that the block is standing and pointing away from the camera (its circles cannot be seen by the camera view)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>List containing the two most probable inclination, this can be “top”, “bottom”, “right” or “left”</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="vision.visione_lab.from_cropped_to_real_world_coord">
<span class="sig-prename descclassname"><span class="pre">vision.visione_lab.</span></span><span class="sig-name descname"><span class="pre">from_cropped_to_real_world_coord</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">point</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/vision/visione_lab.html#from_cropped_to_real_world_coord"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#vision.visione_lab.from_cropped_to_real_world_coord" title="Permalink to this definition"></a></dt>
<dd><p>Simple function for converting a point’s coordinates in a cropped image to the coordinates in the original image taken from the camera (eventually already rescaled)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>point</strong> (<em>tuple</em>) – Coordinates of the point in the cropped image, to be converted back to the original image coordinates</p></li>
<li><p><strong>x1</strong> (<em>Integer</em>) – Minimum 2D coordinate values (for x- and y-axis) in the original image</p></li>
<li><p><strong>y1</strong> (<em>Integer</em>) – Minimum 2D coordinate values (for x- and y-axis) in the original image</p></li>
<li><p><strong>eps</strong> (<em>Integer</em>) – Small delta that was applied before cropping the image in order to avoid losing some contours in Canny algorithm</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>2D coordinates in the original image (x,y)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="vision.visione_lab.from_raw_to_jpg_compliant">
<span class="sig-prename descclassname"><span class="pre">vision.visione_lab.</span></span><span class="sig-name descname"><span class="pre">from_raw_to_jpg_compliant</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/vision/visione_lab.html#from_raw_to_jpg_compliant"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#vision.visione_lab.from_raw_to_jpg_compliant" title="Permalink to this definition"></a></dt>
<dd><p>Transform raw bytes representing image rgb values into a structure which can be saved also as a jpg. The function assumes the input definition is 960x540 and that it is a rgb image,
therefore reading 3 Bytes for each 2D point</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>image that can now be treated and used as a normal jpg image</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="vision.visione_lab.get_inclination">
<span class="sig-prename descclassname"><span class="pre">vision.visione_lab.</span></span><span class="sig-name descname"><span class="pre">get_inclination</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">circles</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img_centre</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/vision/visione_lab.html#get_inclination"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#vision.visione_lab.get_inclination" title="Permalink to this definition"></a></dt>
<dd><p>Apply the least squares polynomial fit in order to find best line that represents the circles’ centers. Based on that and on the distance between the image centre and the average position
of the circles’ centers we get a first estimation whether the block is for example upside-down or turned right</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>circles</strong> (<em>numpy array</em>) – Array of the detected circles</p></li>
<li><p><strong>img_centre</strong> (<em>Tuple</em>) – Center of the detected block</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>rect_center (x,y), rectangle width and height, angle of rotation of the block</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="vision.visione_lab.image_depth_processing">
<span class="sig-prename descclassname"><span class="pre">vision.visione_lab.</span></span><span class="sig-name descname"><span class="pre">image_depth_processing</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/vision/visione_lab.html#image_depth_processing"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#vision.visione_lab.image_depth_processing" title="Permalink to this definition"></a></dt>
<dd><p>Main function called by the callback which transforms the global raw_image to jpg and calls process_image()</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="vision.visione_lab.listener">
<span class="sig-prename descclassname"><span class="pre">vision.visione_lab.</span></span><span class="sig-name descname"><span class="pre">listener</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/vision/visione_lab.html#listener"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#vision.visione_lab.listener" title="Permalink to this definition"></a></dt>
<dd><p>First setup function for establishing the connection with the ROS middleware infrastructure, creating the vision_node, subscribing to the depth and image topics, setting up a publisher for sharing
the results with the other ROS nodes (ex. the robot) and configuring all the other callbacks</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="vision.visione_lab.min_area_rect">
<span class="sig-prename descclassname"><span class="pre">vision.visione_lab.</span></span><span class="sig-name descname"><span class="pre">min_area_rect</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">low_res_mult</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/vision/visione_lab.html#min_area_rect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#vision.visione_lab.min_area_rect" title="Permalink to this definition"></a></dt>
<dd><p>Takes the Canny-filtered image, identifies all the contours in it, sorts those contours based on their size, takes the largest contour as the block’s contour.
Then the function “draws” the smallest rectangle that contains that contour and finds therefore the block’s rotation angle. It also outputs the rectangle’s center and 2D-sizes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>img</strong> (<em>numpy array</em>) – The image filtered through Canny algorithm</p></li>
<li><p><strong>name</strong> (<em>String</em>) – Class of the block</p></li>
<li><p><strong>low_res_mult</strong> (<em>Float</em>) – Parameter necessary due to image scaling</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>rect_center (x,y), rectangle width and height, angle of rotation of the block</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="vision.visione_lab.pca">
<span class="sig-prename descclassname"><span class="pre">vision.visione_lab.</span></span><span class="sig-name descname"><span class="pre">pca</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">to_crop</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/vision/visione_lab.html#pca"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#vision.visione_lab.pca" title="Permalink to this definition"></a></dt>
<dd><p>Read depth values of the 2D points given as input. Transform the 3D points read to a PointCloud and then to a PCA-compatible structure.
Apply Principal Component Analysis to the cropped Point Cloud; this will output how much the 3D directions (x, y, z) influence the 1st and 2nd principal component.
Find which is the cartesian axis which influences the most the first and second Principal Components. Based on that return the final block’s inclination</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>to_crop</strong> (<em>Array</em><em> of </em><em>tuples</em>) – Coordinates of the points we want to use in order to calculate the block’s inclination</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Final block’s inclination</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="vision.visione_lab.process_image">
<span class="sig-prename descclassname"><span class="pre">vision.visione_lab.</span></span><span class="sig-name descname"><span class="pre">process_image</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/vision/visione_lab.html#process_image"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#vision.visione_lab.process_image" title="Permalink to this definition"></a></dt>
<dd><p>Processes image executing the YOLOv5 detection on the specified image and gives as output the detected images cropped around the bounding boxes.</p>
<p>The process is divided in steps:</p>
<ol class="arabic simple">
<li><p>Resize the image in order to adapt it to YoloV5’s training images resolution</p></li>
<li><p>Execute YoloV5 image detection identifying blocks’ classes and bounding boxes</p></li>
<li><p>Remove blocks which are too close one to each other based on their confidence</p></li>
<li><p>For each identified block:</p></li>
</ol>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>image</strong> (<em>numpy array</em>) – The image to execute the detection on</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<section id="output">
<h3>Output<a class="headerlink" href="#output" title="Permalink to this heading"></a></h3>
<dl class="simple">
<dt>block_list: BlockList()</dt><dd><p>List of all detected blocks. Each block is identified by class, 3D position from the camera view, 3D position from the world frame, rotation angle,
confidence of the block taken from Yolo, inclination based on position of circles identified in the block,
final_incl (real 3D position based on Principal Component Analysis of the Point Cloud)cropped around their bounding boxes</p>
</dd>
</dl>
</section>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="vision.visione_lab.processing_callback">
<span class="sig-prename descclassname"><span class="pre">vision.visione_lab.</span></span><span class="sig-name descname"><span class="pre">processing_callback</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/vision/visione_lab.html#processing_callback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#vision.visione_lab.processing_callback" title="Permalink to this definition"></a></dt>
<dd><p>Callback for the main processing part, it is being called every 2 seconds by a rospy Timer. The function waits to acquire both the locks (remaining idle until it has got all of them) and
calls the functions responsible for the whole blocks’ detection process</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="vision.visione_lab.receive_image">
<span class="sig-prename descclassname"><span class="pre">vision.visione_lab.</span></span><span class="sig-name descname"><span class="pre">receive_image</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">msg</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/vision/visione_lab.html#receive_image"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#vision.visione_lab.receive_image" title="Permalink to this definition"></a></dt>
<dd><p>Callback for the RGB image topic, updates the global variable raw_image with the new values. It needs the lock for the rgb image to be acquired before updating it but just continues skipping the update
if the lock is already taken from process_image()</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>msg</strong> (<em>Image</em>) – Entire RGB image read from the camera (definition 960x540)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="vision.visione_lab.receive_pointcloud">
<span class="sig-prename descclassname"><span class="pre">vision.visione_lab.</span></span><span class="sig-name descname"><span class="pre">receive_pointcloud</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">msg</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/vision/visione_lab.html#receive_pointcloud"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#vision.visione_lab.receive_pointcloud" title="Permalink to this definition"></a></dt>
<dd><p>Callback for the point cloud topic, updates the global variable raw_depth with the new values. It needs the lock for the depth to be acquired before updating it but just continues skipping the update
if the lock is already taken from process_image()</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>msg</strong> (<em>PointCloud2</em>) – Entire Point Cloud read from depth camera</p>
</dd>
</dl>
</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Welcome to vision’s documentation!" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="report.html" class="btn btn-neutral float-right" title="Project report" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, matteo.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>